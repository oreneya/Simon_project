# Summary of results

## TensorBoard output


## Test accuracies
* Logistic regression with 100 epochs:                                   0.9222
* Original (two hidden layers) multilayer perceptron with 1000 epochs:   0.8834
* Original (two hidden layers) multilayer perceptron with 100 epochs:    0.9773
* Modified (one hidden layer) multilayer perceptron with 100 epochs: 

## Disscussion

### 1. Did running many more (1,000 vs 100) epochs yield better or worse results for the original multilayer perceptron?

Blah blah.

### 2. Did the multilayer pereceptron do better or worse than logistic regression when you ran them both for 100 epochs?

Blah blah.

### 3. Did decreasing the number of hidden layers reduce the success of the multilayer perceptron?

Blah blah.

### 4. What general lesson might you deduce from your answers to these three questions?

Blah blah.


